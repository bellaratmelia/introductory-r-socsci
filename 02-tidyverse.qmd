---
title: "Data Wrangling with Tidyverse"
author: "Bella Ratmelia"
format: revealjs
---

## Today's Outline

1.  Loading our data into RStudio environment
2.  Data wrangling with `dplyr` and `tidyr` (part of the `tidyverse` package)

## Checklist when you start RStudio

-   Load the project we created last session and open the R script file.
-   Make sure that `Environment` panel is empty (click on broom icon to clean it up)
-   Clear the `Console` and `Plots` too.
-   Re-run the `library(tidyverse)` and `read_csv` portion in the previous session

## Refresher: Loading from CSV into a dataframe

Use `read_csv` from `readr` package (part of `tidyverse`) to load our data into a dataframe

```{r}
#| echo: true
#| message: false
#| output: false

# import tidyverse library
library(tidyverse)

# read the CSV and save into a dataframe called chile_data
chile_data <- read_csv("data/chile_voting.csv")

# "peek at the data, pay attention to the data types!
glimpse(chile_data)
```

## Cleaning data for analysis

::: incremental
-   **Why do it in R?** Because it's much efficient to do so in R, especially if your data is large (e.g. millions of rows, hundreds of columns) and you have repetitive clean up tasks.
-   Incorrect or inconsistent data can lead to false conclusions, so it's important to clean and prep it correctly.
-   Having a clear understanding of the desired data shape is essential as real data often differs from what you imagine! **Refer to codebook, actual questionnaire, appendix for guidance.**
-   Data cleaning techniques differ based on the problems, data type, and the research questions you are trying to answer. Various methods are available, each with its own trade-offs.
:::

## About dplyr and tidyr

-   Packages from `tidyverse`. ([click here to go to the tidyverse homepage](https://www.tidyverse.org/))

-   Posit have created cheatsheets here! (you can have this open in another tab for reference for this session!)

    -   [dplyr cheatsheet](https://rstudio.github.io/cheatsheets/html/data-transformation.html) \| [pdf version](https://rstudio.github.io/cheatsheets/data-transformation.pdf) (I personally prefer this PDF version since it's more visual)

    -   [tidyr cheatsheet](https://rstudio.github.io/cheatsheets/html/tidyr.html) \| [pdf version](https://rstudio.github.io/cheatsheets/tidyr.pdf)

## About the data

The data is from a national survey conducted in April and May of 1988 by FLACSO/Chile, capturing voting intentions for the [1988 Chilean plebiscite](https://en.wikipedia.org/wiki/1988_Chilean_presidential_referendum). The dataset contains information about respondents' demographic characteristics and their voting intentions. This data can also be found from `carData` package! (more on this later)

Key variables in the dataset:

------------------------------------------------------------------------

| Variable     | Description                                                                                                          |
|--------------|----------------------------------------------------------------------------------------------------------------------|
| `region`     | Region of voters: `C` (Central), `M` (Metropolitan Santiago area), `N` (North), `S` (South), `SA` (city of Santiago) |
| `population` | Population size of respondent's community                                                                            |
| `sex`        | Sex of voters: `F` (female), `M` (male)                                                                              |
| `age`        | Age in years                                                                                                         |
| `education`  | Education level of voters: `P` (Primary), `PS` (Post-secondary), `S` (Secondary)                                     |
| `income`     | Monthly income, in Pesos                                                                                             |
| `statusquo`  | Scale of support for the status-quo in numerical value                                                               |
| `vote`       | Voter's decision: `A` (will abstain), `N` (will vote no), `U` (undecided), `Y` (will vote yes)                       |

: Explanatory notes on each column

## Prelim checks for your data

It's good practice to do some preliminary checks on your data to get a better sense of it!

A few things that you can do:

-   Check for duplicates

-   Check for missing values

-   Check on overall distributions of the categorical data

-   Plot the distribution of the numerical/continuous data

## Data wrangling activities specific to our data

**Scenario**: We are a junior Research Assistant (RA) in a research team currently studying about the 1988 Chilean plebiscite. The team's primary goal is to identify any discernible and interesting patterns in the voter demographic data.

As a start, we have been asked to do the following data cleaning and processing tasks:

::: incremental
1.  Remove all rows with empty values (NA)

2.  Separate the demographic information (region, sex, age, education) into a separate CSV called `chile-demographics.csv`

3.  Retrieve only respondents aged 30 or older, arrange it from oldest to youngest, and save it into a separate CSV called `chile-30plus.csv`

4.  Make the character columns such as `region`, `sex`, `education`, and `vote` to be in uppercase.

5.  Convert all the categorical columns such as `region`, `sex`, `education`, and `vote` to Factor. Make sure `education` is ordered.
:::

------------------------------------------------------------------------

::: incremental
6.  Create a new column called `age_group` that categorizes age into groups: "18-29", "30-44", "45-59", "60+".

7.  Create a new column called `high_income` that is TRUE if income is above the median, FALSE otherwise.

8.  Create a new column called `support_level` that categorizes `statusquo` into "Unsupportive" (\<= 0) and "Supportive" (\> 0). Save all of these changes you made from step 3 onwards into a new CSV called `chile_voting_processed.csv`

9.  Generate summary stats of `income` grouped by `region` and `education`. The summary stats should include mean, median, max, min, std, and n (number of observations).

10. Reshape the data to have `region` as rows and `vote` options as columns, with the values being the count of votes for each option in each region.
:::

# Let's wrangle our data!

## Task #1

> **A strategy I'd like to recommend:** briefly read over the `dplyr` + `tidyr` documentation, either the PDF or HTML version, and have them open on a separate tab so that you can refer to it quickly.

Remove all rows with empty values (NA)

```{r}
#| echo: true
#| output: false
chile_data <- chile_data |> 
  drop_na()

```

The number of observations after all rows containing NAs are removed:

```{r}
#| echo: true
dim(chile_data)
```

## Interlude: Pipe Operator ( \|\> )

-   The pipe operator (\|\>) allows us to chain multiple operations without creating intermediate dataframes.

-   Super handy when we perform several data wrangling tasks using tidyverse in sequence.

-   Helps with readability, especially for complex operations.

-   Keyboard shortcut: `Ctrl`+`Shift`+`M` on Windows, `Cmd`+`Shift`+`M` on Mac

::: panel-tabset
### Without pipe operator
Notice that we have to create a "temp" dataframes called `age_df` and `age_df_desc` in this method.

``` r
age_df <- filter(chile_data, age >= 30)
age_df_desc <- arrange(age_df, desc(age))
write_csv(age_df_desc, "data-output/chile-30plus.csv")
```

### With pipe operator

No "temp" dataframe needed here! :D

``` {.r code-overflow="overflow"}
chile_data |> 
    filter(age >= 30) |> 
    arrange(desc(age)) |> 
    write_csv("data-output/chile-30plus.csv")
```
:::

## Task #2

Separate the demographic information (region, sex, age, education) into a separate CSV called `chile-demographics.csv`

```{r}
#| echo: true
#| output: false

# not using the |> operator here!

demographics_df <- select(chile_data, region, sex, age, education)
write_csv(demographics_df, "data-output/chile-demographics.csv")
```

The first few rows in the CSV:

```{r}
chile_data |> 
    select(region, sex, age, education) |> 
    print(n = 3)
```

## Task #3

Retrieve only respondents aged 30 or older, arrange it from oldest to youngest, and save it into a separate CSV called `chile-30plus.csv`

```{r}
#| echo: true

chile_data |> 
    filter(age >= 30) |> 
    arrange(desc(age)) |> 
    write_csv("chile-30plus.csv")
```

The first few rows in the resulting CSV:

```{r}
#| echo: false

chile_data |> 
    filter(age >= 30) |> 
    arrange(desc(age)) |> 
    print(n = 3)
```

## Group exercise 1 (solo attempts ok)

[**Time: 5 minutes!**]{.underline}

Retrieve only respondents from the Metropolitan Santiago area (`M`), with Secondary education (`S`), and who are undecided (`U`) about their vote. Keep only their `region`, `education`, `vote`, and `income` columns in a new dataframe called `santiago_undecided` in **descending** order of `income`.

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "Show answer"

santiago_undecided <- chile_data |> 
    filter(region == "M" & education == "S" & vote == "U") |> 
    select(region, education, vote, income) |> 
    arrange(desc(income)) 
```

The first few rows of `santiago_undecided`:

```{r}
santiago_undecided |> 
    print(n = 3)
```

## Task #4

Make all character columns such as `region`, `sex`, `education`, and `vote` to be in uppercase.

```{r}
#| echo: true

cols_to_change <- c("region", "sex", "education", "vote")
chile_data <- chile_data |> 
    mutate(across(cols_to_change, toupper))
```

The end result:

```{r}
chile_data |> 
    select(region, sex, education, vote) |> 
    print(n = 3)
```

## Task #5

Convert all the categorical columns such as `region`, `sex`, `education`, and `vote` to Factor. Make sure `education` is ordered.

```{r}
#| echo: true

chile_data <- chile_data |> 
    mutate(across(cols_to_change, as.factor))

#reordering
chile_data <- chile_data |> 
    mutate(education = factor(education, 
                         levels = c("P", "S", "PS"), 
                         ordered = TRUE))
```

The structure of education column after the change:

```{r}
str(chile_data["education"])
```

## Task #6

Add a new column to `chile_data` called `age_group` that categorizes age into groups: "18-29", "30-44", "45-59", "60+".

```{r}
#| echo: true

chile_data <- chile_data |> 
    mutate(age_group = case_when(
        age < 30 ~ "18-29",
        age < 45 ~ "30-44",
        age < 60 ~ "45-59",
        TRUE ~ "60+"
    ))
```

The new age_group column should look something like this:

```{r}
chile_data |> 
    select(age, age_group) |> 
    print(n = 4)
```

## Task #7

Create a new column called `high_income` that is TRUE if income is above the median, FALSE otherwise.

hint: you need to calculate the median income first.

```{r}
#| echo: true

median_income <- median(chile_data$income, na.rm = TRUE)
chile_data <- chile_data |> 
    mutate(high_income = income > median_income)
```

The original income column and the new high_income column:

```{r}
chile_data |> 
    select(income, high_income) |> 
    slice(9:11) #print row 9 to row 11
```

## Task #8 - Can you solve this?

Create a new column called `support_level` that categorizes `statusquo` into "Unsupportive" (\<= 0) and "Supportive" (\> 0).

Save all of these changes you made from step 3 onwards into a new CSV called `chile_voting_processed.csv`

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "Show answer"

chile_data <- chile_data |> 
    mutate(support_level = case_when(
        statusquo <= 0 ~ "Unsupportive",
        statusquo > 0 ~ "Supportive",
        TRUE ~ NA_character_
    ))

write_csv(chile_data, "data-output/chile_voting_processed.csv")
```

The new support_level column:

```{r}
chile_data |> 
    select(statusquo, support_level) |> 
    print(n = 3)
```

## Task #9

Generate summary stats of `income` grouped by `region` and `education`. The summary stats should include mean, median, max, min, std, and n (number of observations).

```{r}
#| echo: true
#| output-location: slide

library(gt)
chile_data |> 
    group_by(region, education) |> 
    summarise(observation = n(), 
              mean_income = mean(income, na.rm = TRUE),
              median_income = median(income, na.rm = TRUE), 
              highest = max(income, na.rm = TRUE),
              lowest = min(income, na.rm = TRUE),
              std_dev = sd(income, na.rm = TRUE))
```

## Task #10

Reshape the data to have `region` as rows and `vote` options as columns, with the values being the count of votes for each option in each region.

To achieve this clean table look, we can use `gt` package or `knitr` package!

```{r}
#| echo: true
chile_data |>
    group_by(region, vote) |>
    summarise(count = n(), .groups = "drop") |>
    pivot_wider(names_from = vote, values_from = count, values_fill = 0) |> 
    knitr::kable()
```

## Long vs Wide Data

::: columns
::: {.column width="50%"}
**Long data:**

-   Each row is a unique observation.

-   There is a separate column indicating the variable or type of measurements

-   This format is more "understandable" by R, more suitable for visualizations.

:::

::: {.column width="50%"}
**Wide data:**

-   Each row is a unique observation.

-   Each column is a variable --\> the more variables you have, the "wider" is the data

-   This format is more intuitive for humans!
:::
:::

## Long vs Wide Data: Examples

::: columns
::: {.column width="50%"}
**Long data:**

```{r}
#| echo: false

# Creating the wide data frame
long_data <- chile_data |>
    group_by(region, vote) |>
    summarise(count = n(), .groups = "drop")

# Display the wide data frame
print(long_data)
```
:::

::: {.column width="50%"}
**Wide data:**

```{r}
#| echo: false

long_data |>
    pivot_wider(names_from = "vote", values_from = "count") 
```
:::
:::

## Group exercise 3 (solo attempts ok)

[**Time: 5 minutes**]{.underline}

Generate a summary stats of `age` grouped by `region` and `sex`. The summary stats should include mean, median, max, min, std, and n (number of observations). It should look something like this:

```{r}
#| echo: true
#| code-fold: true
#| output-location: slide
#| code-summary: "Show answer"

chile_data |> 
    group_by(region, sex) |> 
    summarise(observation = n(), 
              mean_age = mean(age, na.rm = TRUE),
              median_age = median(age, na.rm = TRUE), 
              oldest = max(age, na.rm = TRUE),
              youngest = min(age, na.rm = TRUE),
              std_dev = sd(age, na.rm = TRUE))
```

## Bonus: Deleting columns from dataframe

Let's say I have this column called `wrong_column` that I want to remove:

```{r}
#| echo: true

chile_data <- chile_data |> mutate(wrong_column = "random values")
chile_data |> select(region, wrong_column) |> print(n = 3)
```

## Remove the wrong column with subset `-`:

```{r}
#| echo: true
chile_data <- chile_data |> 
    select(-wrong_column)
```

```{r}
chile_data |> select(region) |> print(n = 3)
```

# End of Session 2!

Next session: Descriptive stats and data visualization with `ggplot2` package.
