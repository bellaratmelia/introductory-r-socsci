---
title: "Data Wrangling with Tidyverse"
author: "Bella Ratmelia"
format: revealjs
---

## Today's Outline

1.  Loading our data into RStudio environment
2.  Data wrangling with `dplyr` and `tidyr` (part of the `tidyverse` package)

## Checklist when you start RStudio

-   Load the project we created last session and open the R script file.
-   Make sure that `Environment` panel is empty (click on broom icon to clean it up)
-   Clear the `Console` and `Plots` too.
-   Re-run the `library(tidyverse)` and `read_csv` portion in the previous session

## Refresher: Loading from CSV into a dataframe

Use `read_csv` from `readr` package (part of `tidyverse`) to load our World Values Survey data. More information about the data can be found under the `Dataset` tab in the course website.

```{r}
#| echo: true
#| message: false
#| output: false

# import tidyverse library
library(tidyverse)

# read the CSV and save into a dataframe called wvs_data
wvs_data <- read_csv("data/wvs-wave7-sg-ca-nz.csv")

# "peek" at the data, pay attention to the data types!
glimpse(wvs_data)
```

## Cleaning data for analysis

::: incremental
-   **Why do it in R?** Because it's much efficient to do so in R, especially if your data is large (e.g. millions of rows, hundreds of columns) and you have repetitive clean up tasks.
-   Incorrect or inconsistent data can lead to false conclusions, so it's important to clean and prep it correctly.
-   Having a clear understanding of the desired data shape is essential as real data often differs from what you imagine! **Refer to codebook, actual questionnaire, appendix for guidance.**
-   Data cleaning techniques differ based on the problems, data type, and the research questions you are trying to answer. Various methods are available, each with its own trade-offs.
:::

## About dplyr and tidyr

-   Packages from `tidyverse`. ([click here to go to the tidyverse homepage](https://www.tidyverse.org/))

-   Posit have created cheatsheets here! (you can have this open in another tab for reference for this session!)

    -   [dplyr cheatsheet](https://rstudio.github.io/cheatsheets/html/data-transformation.html) \| [pdf version](https://rstudio.github.io/cheatsheets/data-transformation.pdf) (I personally prefer this PDF version since it's more visual)

    -   [tidyr cheatsheet](https://rstudio.github.io/cheatsheets/html/tidyr.html) \| [pdf version](https://rstudio.github.io/cheatsheets/tidyr.pdf)


## Prelim checks for your data

It's good practice to do some preliminary checks on your data to get a better sense of it!

A few things that you can do:

-   Check for duplicates

-   Check for missing values

-   Check on overall distributions of the categorical data

-   Plot the distribution of the numerical/continuous data

# Data wrangling activities with WVS data

**Scenario**: We are research assistants analyzing patterns in values and satisfaction across different countries and demographic groups. Our team wants to understand how life satisfaction relates to various factors like employment, marital status, and religiosity.

Tasks we need to complete:

::: incremental
1. Remove all rows with missing values (NA)

2. Create a demographics-only dataset with variables like country, sex, age, marital_status, and employment

3. Filter for respondents aged 30 or older, arrange by age (oldest to youngest)

4. Convert categorical variables (country, religiousity, sex, marital_status, employment) to factors

5. Create age groups: "18-29", "30-44", "45-59", "60+"
:::

------------------------------------------------------------------------

::: incremental
6. Create a new column `high_satisfaction` that is TRUE if life_satisfaction is above the median

7. Reverse code scales for all the `importance` variables so that higher numbers consistently represent higher levels of the measured construct. In other words, 1 = Not at all important and 4 = Very important. 

8. Generate summary statistics of life_satisfaction grouped by country and employment status

9. Create a cross-tabulation of religiousity by country

10. Reshape the data to show average satisfaction scores by country and age group
:::


# Let's wrangle our data!

## Task #1

> **A strategy I'd like to recommend:** briefly read over the `dplyr` + `tidyr` documentation, either the PDF or HTML version, and have them open on a separate tab so that you can refer to it quickly.

Remove all rows with empty values (NA)

```{r}
#| echo: true
#| output: false
wvs_data <- wvs_data |> 
  drop_na()
```

The number of observations after removing NAs:

```{r}
#| echo: true
dim(wvs_data)
```

## Interlude: Pipe Operator ( \|\> )

-   The pipe operator (\|\>) allows us to chain multiple operations without creating intermediate dataframes.

-   Super handy when we perform several data wrangling tasks using tidyverse in sequence.

-   Helps with readability, especially for complex operations.

-   Keyboard shortcut: `Ctrl`+`Shift`+`M` on Windows, `Cmd`+`Shift`+`M` on Mac

::: panel-tabset
### Without pipe operator
Notice that we have to create a "temp" dataframes called `age_df` and `age_df_desc` in this method.

``` r
age_df <- filter(wvs_data, age >= 30)
age_df_desc <- arrange(age_df, desc(age))
write_csv(age_df_desc, "data-output/wvs-30plus.csv")
```

### With pipe operator

No "temp" dataframe needed here! :D

``` {.r code-overflow="overflow"}
wvs_data |> 
    filter(age >= 30) |> 
    arrange(desc(age)) |> 
    write_csv("data-output/wvs-30plus.csv")
```
:::

## Task #2

Create a demographics-only dataset:

```{r}
#| echo: true
#| output: false

demographics_df <- wvs_data |>
    select(country, sex, age, marital_status, employment) |>
    write_csv("data-output/wvs_demographics.csv")
```

First few rows of the demographics data:

```{r}
demographics_df |>
    print(n = 3)
```

## Task #3: 

Filter for 30+ age group and sort by age:

```{r}
#| echo: true

wvs_30plus <- wvs_data |>
    filter(age >= 30) |>
    arrange(desc(age)) |>
    write_csv("data-output/wvs_30plus.csv")
```

Preview of the filtered data:

```{r}
wvs_30plus |>
    select(country, age, employment) |>
    print(n = 3)
```

## Group Exercise 1 (5 minutes)

Find all respondents who are:
- From Singapore
- Employed full-time
- Have high life satisfaction (8 or higher)
Save their country, employment, life_satisfaction, and freedom scores, arranged by life_satisfaction in descending order.

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "Show answer"

singapore_satisfied <- wvs_data |>
    filter(country == "SGP" & 
           employment == "Full time" & 
           life_satisfaction >= 8) |>
    select(country, employment, life_satisfaction, freedom) |>
    arrange(desc(life_satisfaction))
```

Preview:
```{r}
singapore_satisfied |>
    print(n = 3)
```

## Task #4: 

Convert categorical variables to factors:

```{r}
#| echo: true

cols_to_factor <- c("country", "religiousity", "sex", 
                    "marital_status", "employment")

wvs_data <- wvs_data |>
    mutate(across(all_of(cols_to_factor), as.factor))
```

Checking the structure:
```{r}
str(wvs_data[cols_to_factor])
```

## Task #5

Add age groups to our dataset:

```{r}
#| echo: true

wvs_data <- wvs_data |>
    mutate(age_group = case_when(
        age < 30 ~ "18-29",
        age < 45 ~ "30-44",
        age < 60 ~ "45-59",
        TRUE ~ "60+"
    ))
```

Preview of age groups:
```{r}
wvs_data |>
    select(age, age_group) |>
    print(n = 4)
```


## Task #6

Create a new column `high_satisfaction` that is TRUE if life_satisfaction is above the median:

```{r}
#| echo: true

# Calculate median life satisfaction
median_satisfaction <- median(wvs_data$life_satisfaction, na.rm = TRUE)

# Create the high_satisfaction column
wvs_data <- wvs_data |>
    mutate(high_satisfaction = life_satisfaction > median_satisfaction)
```

Preview of satisfaction categorization:
```{r}
print(median_satisfaction)
wvs_data |>
    select(life_satisfaction, high_satisfaction) |>
    slice(1:11) # print rows 1 to 10
```

## Task #7

In survey data, we often need to reverse code scales so that higher numbers consistently represent higher levels of the measured construct. In our WVS data:

Original importance scale:

- 1 = Very Important

- 2 = Rather Important

- 3 = Not Very Important

- 4 = Not at all Important

Let's create reverse-coded versions where 4 = highest importance:

```{r}
#| echo: true

wvs_data <- wvs_data |>
    mutate(
        # Reverse code each importance variable (5 minus original value)
        family_importance_r = 5 - family_importance,
        friends_importance_r = 5 - friends_importance,
        leisure_importance_r = 5 - leisure_importance,
        work_importance_r = 5 - work_importance
    )
```

---

Preview of original vs reverse-coded scales:
```{r}
wvs_data |>
    select(family_importance, family_importance_r,
           friends_importance, friends_importance_r,
           leisure_importance, leisure_importance_r,
           work_importance, work_importance_r)|>
    print(n = 3)
```

## Task #8 

Save all our changes to a new CSV file:

```{r}
#| echo: true

# Save the processed data
write_csv(wvs_data, "data-output/wvs_processed.csv")

```

Let's check the `data-output` folder to see if the CSV has been properly created!

## Task #9

generate satisfaction statistics by country and employment:

```{r}
#| echo: true
#| output-location: slide

wvs_data |>
    group_by(country, employment) |>
    summarise(
        n = n(),
        mean_satisfaction = mean(life_satisfaction),
        median_satisfaction = median(life_satisfaction),
        sd_satisfaction = sd(life_satisfaction)
    ) |>
    arrange(country, desc(mean_satisfaction))
```

## Task #10

Create a country by religiosity cross-tabulation:

```{r}
#| echo: true
wvs_data |>
    group_by(country, religiousity) |>
    summarise(count = n(), .groups = "drop") |>
    pivot_wider(
        names_from = religiousity,
        values_from = count,
        values_fill = 0
    ) |>
    knitr::kable()
```

## Long vs Wide Data

::: columns
::: {.column width="50%"}
**Long data:**

-   Each row is a unique observation.

-   There is a separate column indicating the variable or type of measurements

-   This format is more "understandable" by R, more suitable for visualizations.

:::

::: {.column width="50%"}
**Wide data:**

-   Each row is a unique observation.

-   Each column is a variable --\> the more variables you have, the "wider" is the data

-   This format is more intuitive for humans!
:::
:::

## Long vs Wide Data: Examples

::: columns
::: {.column width="50%"}
**Long data:**

```{r}
#| echo: false

# Creating the wide data frame
long_data <- wvs_data |>
    group_by(country, religiousity) |>
    summarise(count = n(), .groups = "drop")

# Display the wide data frame
print(long_data)
```
:::

::: {.column width="50%"}
**Wide data:**

```{r}
#| echo: false

long_data |>
    pivot_wider(names_from = "religiousity", values_from = "count") 
```
:::
:::

## Group exercise 3 (solo attempts ok)

[**Time: 5 minutes**]{.underline}

Generate a summary stats of `age` grouped by `country` and `sex`. The summary stats should include mean, median, max, min, std, and n (number of observations). It should look something like this:

```{r}
#| echo: true
#| code-fold: true
#| output-location: slide
#| code-summary: "Show answer"

wvs_data |> 
    group_by(country, sex) |> 
    summarise(observation = n(), 
              mean_age = mean(age, na.rm = TRUE),
              median_age = median(age, na.rm = TRUE), 
              oldest = max(age, na.rm = TRUE),
              youngest = min(age, na.rm = TRUE),
              std_dev = sd(age, na.rm = TRUE))
```

## Bonus: Deleting columns from dataframe

Let's say I have this column called `wrong_column` that I want to remove:

```{r}
#| echo: true

wvs_data <- wvs_data |> mutate(wrong_column = "random values")
wvs_data |> select(country, wrong_column) |> print(n = 3)
```

## Remove the wrong column with subset `-`:

```{r}
#| echo: true
wvs_data <- wvs_data |> 
    select(-wrong_column)
```

```{r}
wvs_data |> select(country) |> print(n = 3)
```

# End of Session 2!

Next session: Descriptive statistics and data visualization with `ggplot2` package - we'll create visualizations to explore patterns in life satisfaction, values, and demographics across countries!
