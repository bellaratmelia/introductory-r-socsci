---
title: "Data Wrangling with Tidyverse"
author: "Bella Ratmelia"
format: revealjs
---

## Today's Outline

1.  Loading our data into RStudio environment
2.  Data wrangling with `dplyr` and `tidyr` (part of the `tidyverse` package)

## Checklist when you start RStudio

-   Load the project we created last session and open the R script file. Click on `File` \> `Recent Projects...` \> Select the our project from last week.
-   Make sure that `Environment` panel is empty (click on broom icon to clean it up).
-   Clear the `Console` and `Plots` too.
-   Re-run the `library(tidyverse)` and `read_csv` portion in the previous session (the code is also on the next slide if you missed last week's session)

## Refresher: Loading from CSV into a dataframe

Use `read_csv` from `readr` package (part of `tidyverse`) to load our World Values Survey data. More information about the data can be found under the `Dataset` tab in the course website.

```{r}
#| echo: true
#| message: false
#| output: false

# import tidyverse library
library(tidyverse)

# read the CSV and save into a dataframe called wvs_data
wvs_data <- read_csv("data/wvs-wave7-sg-ca-nz.csv")

# "peek" at the data, pay attention to the data types!
glimpse(wvs_data)
```

## Cleaning data for analysis

::: incremental
-   **Why do it in R?** Because it's much efficient to do so in R, especially if your data is large (e.g. millions of rows, thousands of columns) and you have repetitive clean up tasks.
-   Incorrect or inconsistent data can lead to false conclusions, so it's important to clean and prep it correctly.
-   Having a clear understanding of the desired data shape is essential as real data often differs from what you imagine! **Refer to codebook, actual questionnaire, appendix for guidance.**
-   Data cleaning techniques differ based on the problems, data type, and the research questions you are trying to answer. Various methods are available, each with its own trade-offs.
:::

## About dplyr and tidyr

-   Packages from `tidyverse`. ([click here to go to the tidyverse homepage](https://www.tidyverse.org/))

-   Posit have created cheatsheets here! (you can have this open in another tab for reference for this session!)

    -   [dplyr cheatsheet](https://rstudio.github.io/cheatsheets/html/data-transformation.html) \| [pdf version](https://rstudio.github.io/cheatsheets/data-transformation.pdf) (I personally prefer this PDF version since it's more visual)

    -   [tidyr cheatsheet](https://rstudio.github.io/cheatsheets/html/tidyr.html) \| [pdf version](https://rstudio.github.io/cheatsheets/tidyr.pdf)

-   Most of the time, these are the ones that you will use quite often:

    -   `drop_na()` - remove rows with null values

    -   `select()` - to select column(s) from a dataframe

    -   `filter()` - to filter rows based on criteria

    -   `mutate()` - to compute new columns or edit existing ones

    -   `if_else()` and `case_when()` - to be used with mutate when we want to compute/edit columns based on multiple criteria

    -   `group_by()` and `summarize()` - group data and summarize each group

## Scenario: Data wrangling activities with WVS data {.smaller}

**Scenario**: We are research assistants analyzing patterns in values and satisfaction across different countries and demographic groups. 

Our team has been assigned to explore and get insights on how specific factors (employment, work importance, marital status, political alignment, financial satisfaction, and religiosity) may relate to life satisfaction among different generations (Gen Z, Millennials, Gen X, and Baby Boomer), including how they may differ between the 3 countries. 

To ensure the analysis quality, we were instructed to discard incomplete data.

We can break down the tasks as such:

::: incremental
1.  Remove all rows with missing values (NA)

2.  Check for duplicates

3.  Select only the relevant columns: demographic columns, `work_importance`, `life_satisfaction`, `financial_satisfaction`, `religiousity`, `political_scale`, `marital_status`, and `employment`. 

4.  Filter for respondents aged 18 or older. Optionally, we can then arrange the dataset by age (oldest to youngest)

5.  Reverse-code `importance` variables so that higher numbers consistently represent higher levels of the measured construct. In other words, 1 = Not at all important and 4 = Very important.

6.  Create age groups for each generation: "18-28", "29-44", "45-60", "61+"
:::

Once we did all of the wrangling above, we can save this "wrangled" version into another CSV


# Let's wrangle our data!

## Task #1

> **A strategy I'd like to recommend:** briefly read over the `dplyr` + `tidyr` documentation, either the PDF or HTML version, and have them open on a separate tab so that you can refer to it quickly.

Remove all rows with empty values (NA) with `drop_na()`

```{r}
#| echo: true
#| output: false
wvs_data <- wvs_data |> 
  drop_na()
```

The number of observations after removing NAs:

```{r}
#| echo: true
dim(wvs_data)
```

## Task #2

Check for duplicates with `distinct()`

```{r}
#| echo: true
#| output: false

wvs_data <- wvs_data |> 
  distinct(ID, .keep_all = TRUE)
```


(Our data has no duplicates, but this is still a good practice to do, especially if we were combining data from multipe sources)


## Interlude: Pipe Operator ( \|\> )

-   The pipe operator (\|\>) allows us to chain multiple operations without creating intermediate / temporary dataframes.

-   Super handy when we perform several data wrangling tasks using tidyverse in sequence.

-   Helps with readability, especially for complex operations.

-   Keyboard shortcut: `Ctrl`+`Shift`+`M` on Windows, `Cmd`+`Shift`+`M` on Mac

::: panel-tabset
### Without pipe operator

Notice that we have to create a "temp" dataframes called `wvs_data_clean` in this method.

``` r
wvs_data <- drop_na(wvs_data)
wvs_data_clean <- wvs_data_clean(wvs_data, desc(age))
write_csv(wvs_data_clean, "data-output/wvs-clean.csv")
```

### With pipe operator

No "temporary" dataframe needed here! :D

``` {.r code-overflow="overflow"}
wvs_data |> 
    drop_na() |> 
    distinct(ID, .keep_all = TRUE) |> 
    write_csv("data-output/wvs-30plus.csv")
```
:::

## Task #3:

Select only the relevant columns: demographic columns,  `life_satisfaction`, `work_importance`, `financial_satisfaction`, `religiousity`, `political_scale`, `marital_status`, and `employment`.

We can achieve this with `select()`!

```{r}
#| echo: true

wvs_data <- wvs_data |>
    select(country, sex, birthyear, age, life_satisfaction, work_importance, financial_satisfaction, religiousity, political_scale, marital_status, employment) 
```

Preview of the filtered data:

```{r}
wvs_data |> glimpse()
```


## Task #4:

Filter for respondents aged 18 or older. Optionally, we can then arrange the dataset by age (oldest to youngest)


```{r}
#| echo: true

wvs_data <- wvs_data |> 
    filter(age >= 18) |> 
    arrange(desc(age))
```

Checking the structure:

```{r}
head(wvs_data)
```

## Task #5

Reverse-code `work_importance` variables so that higher numbers consistently represent higher levels of the measured construct. In other words, 1 = Not at all important and 4 = Very important.

We can achieve this with `mutate()`!

```{r}
#| echo: true

wvs_data <- wvs_data |>
    mutate(work_importance_r = 5 - work_importance)
```

Preview of age groups:

```{r}
wvs_data |>
    select(work_importance_r, work_importance) |>
    print(n = 5)
```

## Task #6

Create age groups for each generation: "18-28", "29-44", "45-60", "61+"

```{r}
#| echo: true

wvs_data <- wvs_data |>
    mutate(age_group = case_when(
        age <= 28 ~ "18-28",
        age <= 44 ~ "29-44",
        age <= 60 ~ "45-60",
        TRUE ~ "61+"
    ))
```

Preview of age groups:

```{r}
wvs_data |>
    select(age, age_group) |>
    print(n = 4)
```

## Checkpoint 1 - saving our hard work into a CSV file

We have done some cleaning! Let's save this cleaned data into a separate CSV file called "wvs_cleaned_v1.csv"

```{r}
#| echo: true

wvs_data |> write_csv("data-output/wvs_cleaned_v1.csv")

```

Check the data output folder to make sure the CSV is created!

## Group Exercise 1 (5 minutes)

Now that we have a new file, load this new `wvs_cleaned_v1.csv` into a new dataframe called `wvs_cleaned`. Filter to respondents from Singapore who are currently employed full time. Show only the country, the employment status, and age. Use `glimpse()` or `print()` to check the result! (you can chain these functions at the end)

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "Show answer"

library(tidyverse)
wvs_cleaned <- read_csv("data-output/wvs_cleaned_v1.csv")

wvs_cleaned |> 
    filter(country == "SGP" & employment == "Full time") |> 
    select(country, employment, age) |> 
    glimpse()

```


## Scenario: Data wrangling activities with WVS data (continued)

Once we are done with the wrangling part, we can proceed with simple descriptive analysis!

::: incremental

7.  Before we proceed further, convert the appropriate categorical variables (country, religiousity, sex, marital_status, employment) to **Factor**

8.  Generate summary statistics of life_satisfaction grouped by country

9.  Create a new column called `satisfaction_group` that indicate whether each respondent has higher or lower than average `life_satisfaction` 

10. Reshape the data to show average satisfaction scores by country and age group
:::

## Task #7

Let's use the `wvs_cleaned` dataframe for this task.

Convert the appropriate categorical variables (country, religiousity, sex, marital_status, employment) to **Factor**.

We can do this with `mutate()` and `as_factor()` from forcats, another sub-package within tidyverse. 

```{r}
#| echo: true
#| output-location: slide

wvs_cleaned <- wvs_cleaned |> 
    mutate(
        country = as_factor(country),
        religiousity = as_factor(religiousity),
        sex = as_factor(sex),
        marital_status = as_factor(marital_status),
        employment = as_factor(employment)
    )

# check conversion result
str(wvs_cleaned)
```

Rstudio may auto-suggest `as.factor()` from base R. You can use this as well, but `as_factor()` is preferred since we are using tidyverse approach. 

## Task #7 - the shortcut

If we have a lot of columns to convert, that might be troublesome to type! This is where `across()` can come in handy. 

Let's first define a character vector that contains the names of columns we plan to convert.


```{r}
#| echo: true

columns_to_convert <- c("country", "religiousity", "sex", "marital_status", "employment")

```

We will use this vector with `mutate()` and `across()`. We tell tidyverse to convert all of the columns with the help of `all_of()`

```{r}
#| echo: true
#| output-location: slide

wvs_cleaned <- wvs_cleaned |> 
    mutate(across(all_of(columns_to_convert), as_factor))

# check conversion result
str(wvs_cleaned)

```

`across()` is used for applying the same function to multiple columns in a single `mutate()` or `summarise()` operation.


## Task #8

Generate summary statistics  such as count (n), mean, median, and standard deviation of life_satisfaction grouped by country. 

We can achieve this with `group_by()` and `summarise()`

```{r}
#| echo: true
#| output-location: slide

wvs_data |>
    group_by(country, age_group) |>
    summarise(
        n = n(),
        mean_satisfaction = mean(life_satisfaction),
        median_satisfaction = median(life_satisfaction),
        sd_satisfaction = sd(life_satisfaction)
    ) |>
    arrange(country, desc(mean_satisfaction))

```

*What if we want to save this into a CSV? What if we also want to group by country AND age_group?*

## Task #9

Create a new column called `satisfaction_group` that indicate whether each respondent has higher or lower than average `life_satisfaction` 

```{r}
#| echo: true
#| output-location: slide

mean_satisfaction <- mean(wvs_data$life_satisfaction, na.rm = TRUE)

wvs_data |>
    mutate(satisfaction_group = if_else(
        life_satisfaction > mean_satisfaction,
        "higher", # if condition is fulfilled, do this
        "lower" # otherwise, do this
    )) 
```

## Task #10

Show the average satisfaction scores by country and age group in wide data format

```{r}
#| echo: true
wvs_data |>
    group_by(country, age_group) |>
    summarise(
        avg_satisfaction = mean(life_satisfaction, na.rm = TRUE),
    ) |>
    pivot_wider(
        names_from = age_group,
        values_from = avg_satisfaction
    ) 
```

## Long vs Wide Data

::::: columns
::: {.column width="50%"}
**Long data:**

-   Each row is a unique observation.

-   There is a separate column indicating the variable or type of measurements

-   This format is more "understandable" by R, more suitable for visualizations.
:::

::: {.column width="50%"}
**Wide data:**

-   Each row is a unique observation.

-   Each column is a variable --\> the more variables you have, the "wider" is the data

-   This format is more intuitive for humans!
:::
:::::

## Long vs Wide Data: Examples

::::: columns
::: {.column width="50%"}
**Long data:**

```{r}
#| echo: false

# Creating the wide data frame
long_data <- wvs_data |>
    group_by(country, age_group) |>
    summarise(count = n())

# Display the wide data frame
print(long_data)
```
:::

::: {.column width="50%"}
**Wide data:**

```{r}
#| echo: false

long_data |>
    pivot_wider(names_from = "age_group", values_from = "count") 
```
:::
:::::

## Group exercise 2 (solo attempts ok)

[**Time: 5 minutes**]{.underline}

Generate a summary stats of `age` grouped by `country` and `sex`. The summary stats should include mean, median, max, min, std, and n (number of observations). It should look something like this:

```{r}
#| echo: true
#| code-fold: true
#| output-location: slide
#| code-summary: "Show answer"

wvs_data |> 
    group_by(country, sex) |> 
    summarise(observation = n(), 
              mean_age = mean(age, na.rm = TRUE),
              median_age = median(age, na.rm = TRUE), 
              oldest = max(age, na.rm = TRUE),
              youngest = min(age, na.rm = TRUE),
              std_dev = sd(age, na.rm = TRUE))
```

## Bonus: Deleting columns from dataframe

Let's say I have this column called `wrong_column` that I want to remove:

```{r}
#| echo: true

wvs_data <- wvs_data |> mutate(wrong_column = "random values")
wvs_data |> select(country, wrong_column) |> print(n = 3)
```

## Remove the wrong column with subset `-`:

```{r}
#| echo: true
wvs_data <- wvs_data |> 
    select(-wrong_column)
```

```{r}
wvs_data |> select(country) |> print(n = 3)
```


# End of Session 2!

Next session: Descriptive statistics and data visualization with `ggplot2` package - we'll create visualizations to explore patterns in life satisfaction, values, and demographics across countries!
