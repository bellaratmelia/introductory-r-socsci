---
title: "Data Wrangling with Tidyverse"
author: "Bella Ratmelia"
format: revealjs
---

## Today's Outline

1.  Loading our data into RStudio environment
2.  Data wrangling with `dplyr` and `tidyr` (part of the `tidyverse` package)

## Checklist when you start RStudio

-   Navigate to where you create your R project folder for this workshop.
-   Find a file with `.Rproject` extension and double-click on it. This will start RStudio and open your project. 
-   Make sure that `Environment` panel is empty (click on broom icon to clean it up).
-   Clear the `Console` and `Plots` too.
-   Re-run the `library(tidyverse)` and `read_csv` portion in the previous session (the code is also on the next slide if you missed last week's session)

## Refresher: Loading from CSV into a dataframe

Use `read_csv` from `readr` package (part of `tidyverse`) to load our World Values Survey data. More information about the data can be found under the `Dataset` tab in the course website.

```{r}
#| echo: true
#| message: false
#| output: false

# import tidyverse library
library(tidyverse)

# read the CSV and save into a dataframe called wvs_data
wvs_data <- read_csv("data/wvs-wave7-sg-ca-nz.csv")

# "peek" at the data, pay attention to the data types!
glimpse(wvs_data)
```

## Why do we need to clean our data?

::: incremental
-   Researchers spend 60-80% of their time on data preparation - investing in proper wrangling upfront saves hours of debugging and rework later.
-   Poor data quality costs projects or organizations millions annually(!), and even one misclassified data point can skew entire analyses.
-   Clean data improves the workflow for statistical tests and can reveal hidden patterns that aren't visible in messy datasets
-   Well-documented data cleaning makes research transparent and reproducible, benefiting both future-you and collaborators.

:::

## Why do it in R? Can't I do this on excel?

::: incremental
-   R code creates a permanent record of exactly what you did - Excel clicks and manual edits are hard to track and reproduce (unless you note down what you did).
-   R handles dates, times, text, and mixed data types much more reliably than Excel.
-   Excel can automatically "correct" your data in unwanted ways (like converting your dates from DDMMYY to MMDDYY)
-   Write the cleaning code once, apply it to multiple datasets or when data updates. Whereas Excel requires manual repetition of the same steps each time.
-   Complex joins, reshaping, and conditional operations that would take many Excel steps can be done in a few lines of R code.
-   R scripts can be easily shared, version controlled, and integrated into reproducible workflows

:::

## What do I need to know before we begin?

::: incremental
-   Always examine your data first (`glimpse()`, `summary()`, `str()`) before cleaning.
-   **Never overwrite your raw data files** 
-   Budget extra time for data cleaning - it almost always takes longer than expected!
-   Having a clear understanding of the desired data shape is essential as real data often differs from what you imagine! **Refer to codebook, actual questionnaire, appendix for guidance.**
-   Look out for outliers!
-   Remember: Data cleaning techniques differ based on the problems, data type, and the research questions you are trying to answer. Various methods are available, each with its own trade-offs.

:::


## The tools we're going to use: dplyr and tidyr from tidyverse

-   Packages from `tidyverse`. ([click here to go to the tidyverse homepage](https://www.tidyverse.org/))

-   Posit have created cheatsheets here! (you can have this open in another tab for reference for this session!)

    -   [dplyr cheatsheet](https://rstudio.github.io/cheatsheets/html/data-transformation.html) \| [pdf version](https://rstudio.github.io/cheatsheets/data-transformation.pdf) (I personally prefer this PDF version since it's more visual)

    -   [tidyr cheatsheet](https://rstudio.github.io/cheatsheets/html/tidyr.html) \| [pdf version](https://rstudio.github.io/cheatsheets/tidyr.pdf)

-   Most of the time, these are the ones that you will use quite often:

    -   `drop_na()` - remove rows with null values

    -   `select()` - to select column(s) from a dataframe

    -   `filter()` - to filter rows based on criteria

    -   `mutate()` - to compute new columns or edit existing ones

    -   `if_else()` and `case_when()` - to be used with mutate when we want to compute/edit columns based on multiple criteria

    -   `group_by()` and `summarize()` - group data and summarize each group
    
## More advanced ones which is not covered in the workshop (see appendix for examples)

-   Joining multiple dataframes' columns: `left_join()`, `right_join()`, `inner_join()`, `full_join()`
    
-   Joining multiple dataframes' rows: `bind_rows()`
    
-   Splitting or combining cells: `unite()`, `separate_wider_delim()`, `separate_long_delim()`
    
Additionally: you may need the [forcats](https://forcats.tidyverse.org/articles/forcats.html) cheatsheet here: <https://raw.githubusercontent.com/rstudio/cheatsheets/main/factors.pdf>

forcats is also part of tidyverse, specifically used to handle factor data. 


## Why are we using tidyverse? Is it a must?

It's not a must, but it'll be make our job much easier! Key advantages:

-   More 'English' looking code and thus more intuitive for beginners
-   Tidyverse follow consistent syntax patterns - first argument is always the data to work on, followed by the function name i.e the things that we want to do on to the data. 
-   Tidyverse gives clearer, more helpful error messages

Example:
```r
# Base R
subset_data <- data[data$age > 18 & data$income > 50000, c("name", "age", "salary")]

# Tidyverse  
subset_data <- data |> 
  filter(age > 18, income > 50000)  |> 
  select(name, age, salary)

```

## Scenario: Data wrangling activities with WVS data {.smaller}

**Scenario**: We are research assistants analyzing patterns in values and satisfaction across different countries and demographic groups.

Our team has been assigned to explore and get insights on how specific factors (employment, work importance, marital status, political alignment, financial satisfaction, and religiosity) may relate to life satisfaction among different generations (Gen Z, Millennials, Gen X, and Baby Boomer), including how they may differ between the 3 countries.

To ensure the analysis quality, we were instructed to discard incomplete data.

We can break down the steps as such:

::: incremental
1.  Remove all rows with missing values (NA)

2.  Check for duplicates

3.  Select only the relevant columns: participants' `ID`, demographic columns (i.e. `age`, `country`, `sex`, `birthyear`), `work_importance`, `life_satisfaction`, `financial_satisfaction`, `religiousity`, `political_scale`, `marital_status`, and `employment`.

4.  Filter for respondents aged 18 or older. Optionally, we can then arrange the dataset by age (oldest to youngest)

5.  Reverse-code `importance` variables so that higher numbers consistently represent higher levels of the measured construct. In other words, 1 = Not at all important and 4 = Very important.

6.  Create age groups for each generation: "18-28", "29-44", "45-60", "61+"
:::

Once we did all of the wrangling above, we can save this "wrangled" version into another CSV as a "checkpoint".

# Let's wrangle our data!

## Step #1

> **A strategy I'd like to recommend:** briefly read over the `dplyr` + `tidyr` documentation, either the PDF or HTML version, and have them open on a separate tab so that you can refer to it quickly.

Remove all rows with empty values (NA) with `drop_na()`

```{r}
#| echo: true
#| output: false
wvs_data <- wvs_data |> 
  drop_na()
```

The number of observations after removing NAs:

```{r}
#| echo: true
dim(wvs_data)
```

## Interlude: Pipe Operator ( \|\> )

-   The pipe operator (\|\>) allows us to chain multiple operations without creating intermediate / temporary dataframes.

-   Super handy when we perform several data wrangling tasks using tidyverse in sequence.

-   Helps with readability, especially for complex operations.

-   Keyboard shortcut: `Ctrl`+`Shift`+`M` on Windows, `Cmd`+`Shift`+`M` on Mac

::: panel-tabset
### Without pipe operator

Notice that we have to create a "temp" dataframes called `wvs_data_clean` in this method.

``` r
wvs_data <- drop_na(wvs_data)
wvs_data_clean <- wvs_data_clean(wvs_data, desc(age))
write_csv(wvs_data_clean, "data-output/wvs-clean.csv")
```

### With pipe operator

No "temporary" dataframe needed here! :D

``` {.r code-overflow="overflow"}
wvs_data |> 
    drop_na() |> 
    distinct(ID, .keep_all = TRUE) |> 
    write_csv("data-output/wvs-30plus.csv")
```
:::

## Step #2

Check for duplicates with `distinct()`

```{r}
#| echo: true
#| output: false

wvs_data <- wvs_data |> 
  distinct(ID, .keep_all = TRUE)
```

(Our data has no duplicates, but this is still a good practice to do, especially if we were combining data from multipe sources)

## Step #3:

Select only the relevant columns: demographic columns, `life_satisfaction`, `work_importance`, `financial_satisfaction`, `religiousity`, `political_scale`, `marital_status`, and `employment`.

We can achieve this with `select()`!

```{r}
#| echo: true

wvs_data <- wvs_data |>
    select(ID, country, sex, birthyear, age, life_satisfaction, work_importance, financial_satisfaction, religiousity, political_scale, marital_status, employment) 
```

Preview of the filtered data:

```{r}
wvs_data |> glimpse()
```

## Step #4:

Filter for respondents aged 18 or older. Optionally, we can then arrange the dataset by age (oldest to youngest)

```{r}
#| echo: true

wvs_data <- wvs_data |> 
    filter(age >= 18) |> 
    arrange(desc(age))
```

Checking the structure:

```{r}
head(wvs_data)
```

## Step #5

Reverse-code `work_importance` variables so that higher numbers consistently represent higher levels of the measured construct. In other words, 1 = Not at all important and 4 = Very important.

We can achieve this with `mutate()`!

```{r}
#| echo: true

wvs_data <- wvs_data |>
    mutate(work_importance_r = 5 - work_importance)
```

Preview of age groups:

```{r}
wvs_data |>
    select(work_importance_r, work_importance) |>
    print(n = 5)
```

## Step #6

Create age groups for each generation: "18-28", "29-44", "45-60", "61+"

```{r}
#| echo: true

wvs_data <- wvs_data |>
    mutate(age_group = case_when(
        age <= 28 ~ "18-28",
        age <= 44 ~ "29-44",
        age <= 60 ~ "45-60",
        TRUE ~ "61+"
    ))
```

Preview of age groups:

```{r}
wvs_data |>
    select(age, age_group) |>
    print(n = 4)
```

## Checkpoint 1 - saving our hard work into a CSV file

We have done some cleaning! Let's save this cleaned data into a separate CSV file called "wvs_cleaned_v1.csv"

```{r}
#| echo: true

wvs_data |> write_csv("data-output/wvs_cleaned_v1.csv")

```

Check the data output folder to make sure the CSV is created!


## Simple descriptive analysis

Once we are done with the wrangling part, we can proceed with simple descriptive analysis!

::: incremental
-   Prep: Before we proceed further, convert the appropriate categorical variables (country, religiousity, sex, marital_status, employment) to **Factor**

-   Analysis 1: Generate summary statistics of life_satisfaction grouped by country

-   Analysis 2: Create a new column called `satisfaction_group` that indicate whether each respondent has higher or lower than average `life_satisfaction`

-   Analysis 3: Reshape the data to show average satisfaction scores by country and age group
:::

## Prep before analysis: convert to factors

Let's use the `wvs_cleaned` dataframe for this task.

Convert the appropriate categorical variables (country, religiousity, sex, marital_status, employment) to **Factor**.

We can do this with `mutate()` and `as_factor()` from forcats, another sub-package within tidyverse.

```{r}
#| echo: true
#| output-location: slide

wvs_cleaned <- read_csv("data-output/wvs_cleaned_v1.csv")
wvs_cleaned <- wvs_cleaned |> 
    mutate(
        country = as_factor(country),
        religiousity = as_factor(religiousity),
        sex = as_factor(sex),
        marital_status = as_factor(marital_status),
        employment = as_factor(employment)
    )

# check conversion result
str(wvs_cleaned)
```

Rstudio may auto-suggest `as.factor()` from base R. You can use this as well, but `as_factor()` is preferred since we are using tidyverse approach.

## Prep before analysis: convert to factors (shortcut ver.)

If we have a lot of columns to convert, that might be troublesome to type! This is where `across()` can come in handy.

Let's first define a character vector that contains the names of columns we plan to convert.

```{r}
#| echo: true

columns_to_convert <- c("country", "religiousity", "sex", "marital_status", "employment")

```

We will use this vector with `mutate()` and `across()`. We tell tidyverse to convert all of the columns with the help of `all_of()`

```{r}
#| echo: true
#| output-location: slide

wvs_cleaned <- wvs_cleaned |> 
    mutate(across(all_of(columns_to_convert), as_factor))

# check conversion result
str(wvs_cleaned)

```

`across()` is used for applying the same function to multiple columns in a single `mutate()` or `summarise()` operation.

## Analysis 1 - summary stats of life_satisfaction for each country

Generate summary statistics such as count (n), mean, median, and standard deviation of life_satisfaction grouped by country.

We can achieve this with `group_by()` and `summarise()`

```{r}
#| echo: true
#| output-location: slide

wvs_data |>
    group_by(country, age_group) |>
    summarise(
        n = n(),
        mean_satisfaction = mean(life_satisfaction),
        median_satisfaction = median(life_satisfaction),
        sd_satisfaction = sd(life_satisfaction)
    ) |>
    arrange(country, desc(mean_satisfaction))

```

*What if we want to save this into a CSV? What if we also want to group by country AND age_group?*

## Analysis 2 - How many has below and average life_satisfaction?

Create a new column called `satisfaction_group` that indicate whether each respondent has higher or lower than average `life_satisfaction`

```{r}
#| echo: true
#| output-location: slide

mean_satisfaction <- mean(wvs_data$life_satisfaction, na.rm = TRUE)

wvs_data |>
    mutate(satisfaction_group = if_else(
        life_satisfaction > mean_satisfaction, # the condition to evaluate
        "higher", # if condition is fulfilled, do this
        "lower" # otherwise, do this
    )) 
```

## Analysis 3 - What's the average satisfaction scores for each country and age group?

Show the average satisfaction scores by country and age group in wide data format

```{r}
#| echo: true
wvs_data |>
    group_by(country, age_group) |>
    summarise(
        avg_satisfaction = mean(life_satisfaction, na.rm = TRUE),
    ) |>
    pivot_wider(
        names_from = age_group,
        values_from = avg_satisfaction
    ) 
```

## Long vs Wide Data

::::: columns
::: {.column width="50%"}
**Long data:**

-   Each row is a unique observation.

-   There is a separate column indicating the variable or type of measurements

-   This format is more "understandable" by R, more suitable for visualizations (which we'll explore more next week!)
:::

::: {.column width="50%"}
**Wide data:**

-   Each row is a value in variables.

-   Each column is a value in variables --\> the more values you have, the "wider" is the data

-   This format is more intuitive for humans!
:::
:::::

## Long vs Wide Data: Examples

::::: columns
::: {.column width="50%"}
**Long data:**

```{r}
#| echo: false

library(kableExtra)

# Creating the wide data frame
long_data <- wvs_data |>
    group_by(country, age_group) |>
    summarise(count = n()) 

long_data |> 
    kbl(caption = "Observations (Long)")  |> 
    kable_styling(bootstrap_options = c("striped", "bordered"), font_size = "85%")

```
:::

::: {.column width="50%"}
**Wide data:**

```{r}
#| echo: false

long_data |>
    pivot_wider(names_from = "age_group", values_from = "count") |> 
    kbl(caption = "Observations (Wide)") |> 
    kable_styling(bootstrap_options = c("striped", "bordered"), font_size = "85%")
```
:::
:::::


## Bonus: Deleting columns from dataframe

Let's say I have this column called `wrong_column` that I want to remove:

```{r}
#| echo: true

wvs_data <- wvs_data |> mutate(wrong_column = "random values")
wvs_data |> select(country, wrong_column) |> print(n = 3)
```

## Remove the wrong column with subset `-`:

```{r}
#| echo: true
wvs_data <- wvs_data |> 
    select(-wrong_column)
```

```{r}
wvs_data |> select(country) |> print(n = 3)
```

# Recap

::: incremental

-   Import and read data into RStudio: Load external data files (like CSV or Excel) into R using functions such as `read_csv()` to make the data available for analysis.

-   Data wrangling with dplyr and tidyr (part of the tidyverse package): Use tidyverse functions to tidy and reshape datasets and perform tasks like selecting, filtering, and summarizing data.

-   Remove all rows with missing values (NA) and check for duplicates: Delete rows containing missing data using `na.omit()` and identify or remove duplicate rows with functions like `distinct()`.

-   Select only the relevant columns: Use `select()` to keep only the columns needed for the analysis, focusing on important variables.

-   Filter data based on criterion and arrange data: Apply `filter()` to keep rows meeting specific conditions and use `arrange()` to sort data by one or more columns.

-   Change factor level values: Modify the categories of a factor using `factor()` or `recode()` to rename or reorder levels for clearer analysis.

-   Create new columns: Generate or modify columns using `mutate()`, often by transforming or combining existing columns.

:::

# End of Session 2!

Next session: Descriptive statistics and data visualization with `ggplot2` package - we'll create visualizations to explore patterns in life satisfaction, values, and demographics across countries!

## To try at home: Exercise 1

Now that we have a new file, load this new `wvs_cleaned_v1.csv` into a new dataframe called `wvs_cleaned`. Filter to respondents from Singapore who are currently employed full time. Show only the Respondent ID, country, the employment status, and age. Use `glimpse()` or `print()` to check the result! (you can chain these functions at the end)

**Step 1**: Load the new file

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "Show answer"
#| output: false

library(tidyverse)
wvs_cleaned <- read_csv("data-output/wvs_cleaned_v1.csv")
```

------------------------------------------------------------------------

**Step 2**: Do the filtering and selecting, and then show result

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "Show answer"

library(tidyverse)
wvs_cleaned <- read_csv("data-output/wvs_cleaned_v1.csv")

wvs_cleaned |> 
    filter(country == "SGP" & employment == "Full time") |> 
    select(ID, country, employment, age) |> 
    glimpse()

```


## To try at home: Exercise 2

Generate a summary stats of `age` grouped by `country` and `sex`. The summary stats should include mean, median, max, min, std, and n (number of observations). It should look something like this:

```{r}
#| echo: true
#| code-fold: true
#| output-location: slide
#| code-summary: "Show answer"

wvs_data |> 
    group_by(country, sex) |> 
    summarise(observation = n(), 
              mean_age = mean(age, na.rm = TRUE),
              median_age = median(age, na.rm = TRUE), 
              oldest = max(age, na.rm = TRUE),
              youngest = min(age, na.rm = TRUE),
              std_dev = sd(age, na.rm = TRUE))
```

# Appendix
Advanced tidyr and dplyr features you may need in the future. 

## Joining DataFrames by column

Let's assume we have two DataFrames `customers` and `orders`

:::: {.columns}

::: {.column width="50%"}
`customers` dataframe:

(Notice that the ID is 1, 2, and 3)
```{r}

customers <- data.frame(id = 1:3, name = c("Alice", "Bob", "Carol"))
print(customers)
```
:::

::: {.column width="50%"}
`orders` dataframe

(Notice that the ID is 1, 2, and 4)
```{r}

orders <- data.frame(id = c(1,2,4), amount = c(100, 200, 150))
print(orders)

```
:::

::::


## left_join() to keep all rows from the left table i.e. customers
```{r}
#| echo: true

customers |> left_join(orders, by = "id")

```

## right_join() to keep all rows from the right table i.e. orders
```{r}
#| echo: true

customers |> right_join(orders, by = "id")

```


## inner_join() to keep only matching rows
```{r}
#| echo: true

customers |> inner_join(orders, by = "id")

```

## full_join() to keep all rows from both tables
```{r}
#| echo: true

customers |> full_join(orders, by = "id")
```


## bind_rows() to stack rows from two different dataframes

Let's say we have the following dataframes
```{r}
df1 <- data.frame(name = "Alice", age = 25)
df2 <- data.frame(name = "Bob", age = 30)
```
```{r}
#| echo: true
print(df1)
```

```{r}
#| echo: true
print(df2)
```

Stack them together:
```{r}
#| echo: true

df1 |> bind_rows(df2)

```

## Splitting and combining cells

Let's say we have the following dataframe

```{r}

df <- data.frame(
  first = c("John", "Jane"),
  last = c("Doe", "Smith"),
  full_address = c("123 Main St, NYC, NY", "456 Oak Ave, LA, CA")
)

print(df)
```


## Combine first and last name columns into one
```{r}
#| echo: true

df <- df |> unite("full_name", "first", "last", sep = "_")
print(df)
```

## Split the full name column into multiple (by delimiter)
```{r}
#| echo: true

df <- df |> separate_wider_delim("full_name", delim = "_", names = c("first", "last"))
print(df)
```

## Split one column into multiple rows (long format)
```{r}
#| echo: true

df |> separate_longer_delim(full_address, delim = ", ")


```


